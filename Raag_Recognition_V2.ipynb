{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Concatenate, Dropout, Masking, Attention, Add, Reshape"
      ],
      "metadata": {
        "id": "HU9lGSW2_rsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Extraction**"
      ],
      "metadata": {
        "id": "pyTZpNKWABGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_audio(y, sr):\n",
        "    # Time stretching\n",
        "    if np.random.random() < 0.5:\n",
        "        rate = np.random.uniform(0.9, 1.1)  # ±10% speed change\n",
        "        y = librosa.effects.time_stretch(y, rate=rate)\n",
        "\n",
        "    # Pitch shifting\n",
        "    if np.random.random() < 0.5:\n",
        "        n_steps = np.random.randint(-2, 3)  # ±2 semitones\n",
        "        y = librosa.effects.pitch_shift(y, sr=sr, n_steps=n_steps)\n",
        "\n",
        "    # Adding noise\n",
        "    if np.random.random() < 0.5:\n",
        "        noise = np.random.normal(0, 0.005, y.shape)\n",
        "        y = y + noise\n",
        "\n",
        "    return y\n",
        "\n",
        "def extract_features(file_path, segment_length=2, hop_length=1, sr=22050):\n",
        "    y, sr = librosa.load(file_path, sr=sr)\n",
        "    y = augment_audio(y, sr)\n",
        "    segment_samples = int(segment_length * sr)\n",
        "    hop_samples = int(hop_length * sr)\n",
        "\n",
        "    segments = librosa.util.frame(y, frame_length=segment_samples, hop_length=hop_samples)\n",
        "\n",
        "    mfccs_list = []\n",
        "    chroma_list = []\n",
        "    spectral_contrast_list = []\n",
        "    tonnetz_list = []\n",
        "\n",
        "    for segment in segments.T:\n",
        "        mfccs = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=13).T\n",
        "        chroma = librosa.feature.chroma_stft(y=segment, sr=sr).T\n",
        "        spectral_contrast = librosa.feature.spectral_contrast(y=segment, sr=sr).T\n",
        "        tonnetz = librosa.feature.tonnetz(y=segment, sr=sr).T\n",
        "\n",
        "        mfccs_list.append(mfccs)\n",
        "        chroma_list.append(chroma)\n",
        "        spectral_contrast_list.append(spectral_contrast)\n",
        "        tonnetz_list.append(tonnetz)\n",
        "\n",
        "    return np.array(mfccs_list), np.array(chroma_list), np.array(spectral_contrast_list), np.array(tonnetz_list)\n",
        "\n",
        "def save_features(file_path, feature_save_dir, mfccs, chroma, spectral_contrast, tonnetz):\n",
        "    base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
        "    if not os.path.exists(feature_save_dir):\n",
        "        os.makedirs(feature_save_dir)\n",
        "    with open(os.path.join(feature_save_dir, base_filename + '_mfccs.pkl'), 'wb') as f:\n",
        "        pickle.dump(mfccs, f)\n",
        "    with open(os.path.join(feature_save_dir, base_filename + '_chroma.pkl'), 'wb') as f:\n",
        "        pickle.dump(chroma, f)\n",
        "    with open(os.path.join(feature_save_dir, base_filename + '_spectral_contrast.pkl'), 'wb') as f:\n",
        "        pickle.dump(spectral_contrast, f)\n",
        "    with open(os.path.join(feature_save_dir, base_filename + '_tonnetz.pkl'), 'wb') as f:\n",
        "        pickle.dump(tonnetz, f)\n",
        "\n",
        "def load_data(data_dir, feature_dir):\n",
        "    labels = []\n",
        "    for label in os.listdir(data_dir):\n",
        "        label_dir = os.path.join(data_dir, label)\n",
        "        if not os.path.isdir(label_dir):\n",
        "            continue\n",
        "        label_feature_dir = os.path.join(feature_dir, label)\n",
        "        if not os.path.exists(label_feature_dir):\n",
        "            os.makedirs(label_feature_dir)\n",
        "        for file_name in os.listdir(label_dir):\n",
        "            file_path = os.path.join(label_dir, file_name)\n",
        "            if file_path.endswith('.wav'):  # Ensure only audio files are processed\n",
        "                mfccs, chroma, spectral_contrast, tonnetz = extract_features(file_path)\n",
        "                save_features(file_path, label_feature_dir, mfccs, chroma, spectral_contrast, tonnetz)\n",
        "                labels.append(label)\n",
        "    return labels\n",
        "\n",
        "def load_features_from_files(feature_dir):\n",
        "    mfccs_list = []\n",
        "    chroma_list = []\n",
        "    spectral_contrast_list = []\n",
        "    tonnetz_list = []\n",
        "    labels = []\n",
        "\n",
        "    for label in os.listdir(feature_dir):\n",
        "        label_dir = os.path.join(feature_dir, label)\n",
        "        if not os.path.isdir(label_dir):\n",
        "            continue\n",
        "        for file_name in os.listdir(label_dir):\n",
        "            if not file_name.endswith('_mfccs.pkl'):\n",
        "                continue\n",
        "            base_filename = file_name.replace('_mfccs.pkl', '')\n",
        "            with open(os.path.join(label_dir, base_filename + '_mfccs.pkl'), 'rb') as f:\n",
        "                mfccs = pickle.load(f)\n",
        "            with open(os.path.join(label_dir, base_filename + '_chroma.pkl'), 'rb') as f:\n",
        "                chroma = pickle.load(f)\n",
        "            with open(os.path.join(label_dir, base_filename + '_spectral_contrast.pkl'), 'rb') as f:\n",
        "                spectral_contrast = pickle.load(f)\n",
        "            with open(os.path.join(label_dir, base_filename + '_tonnetz.pkl'), 'rb') as f:\n",
        "                tonnetz = pickle.load(f)\n",
        "\n",
        "            mfccs_list.append(mfccs)\n",
        "            chroma_list.append(chroma)\n",
        "            spectral_contrast_list.append(spectral_contrast)\n",
        "            tonnetz_list.append(tonnetz)\n",
        "            labels.append(label)\n",
        "\n",
        "    return mfccs_list, chroma_list, spectral_contrast_list, tonnetz_list, labels\n",
        "\n",
        "def prepare_data(data_dir, feature_dir):\n",
        "    # Extract and save features\n",
        "    labels = load_data(data_dir, feature_dir)\n",
        "\n",
        "    # Load features from saved files\n",
        "    mfccs_list, chroma_list, spectral_contrast_list, tonnetz_list, labels = load_features_from_files(feature_dir)\n",
        "\n",
        "    # Pad sequences to ensure uniform input length for each feature type\n",
        "    X_mfccs = pad_sequences(mfccs_list, padding='post', dtype='float32', value=-1)\n",
        "    X_chroma = pad_sequences(chroma_list, padding='post', dtype='float32', value=-1)\n",
        "    X_spectral_contrast = pad_sequences(spectral_contrast_list, padding='post', dtype='float32', value=-1)\n",
        "    X_tonnetz = pad_sequences(tonnetz_list, padding='post', dtype='float32', value=-1)\n",
        "    y = np.array(labels)\n",
        "\n",
        "    # Encode labels\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(y)\n",
        "\n",
        "    # Split the data\n",
        "    X_mfccs_train, X_mfccs_test, y_train, y_test = train_test_split(X_mfccs, y_encoded, test_size=0.2, random_state=42)\n",
        "    X_chroma_train, X_chroma_test = train_test_split(X_chroma, test_size=0.2, random_state=42)\n",
        "    X_spectral_contrast_train, X_spectral_contrast_test = train_test_split(X_spectral_contrast, test_size=0.2, random_state=42)\n",
        "    X_tonnetz_train, X_tonnetz_test = train_test_split(X_tonnetz, test_size=0.2, random_state=42)\n",
        "\n",
        "    return (X_mfccs_train, X_chroma_train, X_spectral_contrast_train, X_tonnetz_train, y_train), \\\n",
        "           (X_mfccs_test, X_chroma_test, X_spectral_contrast_test, X_tonnetz_test, y_test), le\n",
        "\n",
        "# Use this function to prepare the data\n",
        "data_dir = '/content/drive/MyDrive/SMLRAAG'  # Update this path to your data directory\n",
        "feature_dir = '/content/drive/MyDrive/SMLRAAG_features'  # Update this path to your feature directory\n",
        "\n"
      ],
      "metadata": {
        "id": "y2xHziJH_vx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Model*"
      ],
      "metadata": {
        "id": "3vQ9U9GqAIk6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLdIwKTJrsOE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Concatenate, Dropout, BatchNormalization, Reshape, LSTM, Bidirectional\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
        "import tensorflow as tf\n",
        "\n",
        "# Function to load features from files\n",
        "def load_features_from_files(feature_dir):\n",
        "    mfccs_list = []\n",
        "    chroma_list = []\n",
        "    spectral_contrast_list = []\n",
        "    tonnetz_list = []\n",
        "    labels = []\n",
        "\n",
        "    for label in os.listdir(feature_dir):\n",
        "        label_dir = os.path.join(feature_dir, label)\n",
        "        if not os.path.isdir(label_dir):\n",
        "            continue\n",
        "        for file_name in os.listdir(label_dir):\n",
        "            if not file_name.endswith('_mfccs.pkl'):\n",
        "                continue\n",
        "            base_filename = file_name.replace('_mfccs.pkl', '')\n",
        "            with open(os.path.join(label_dir, base_filename + '_mfccs.pkl'), 'rb') as f:\n",
        "                mfccs = pickle.load(f)\n",
        "            with open(os.path.join(label_dir, base_filename + '_chroma.pkl'), 'rb') as f:\n",
        "                chroma = pickle.load(f)\n",
        "            with open(os.path.join(label_dir, base_filename + '_spectral_contrast.pkl'), 'rb') as f:\n",
        "                spectral_contrast = pickle.load(f)\n",
        "            with open(os.path.join(label_dir, base_filename + '_tonnetz.pkl'), 'rb') as f:\n",
        "                tonnetz = pickle.load(f)\n",
        "\n",
        "            mfccs_list.append(mfccs)\n",
        "            chroma_list.append(chroma)\n",
        "            spectral_contrast_list.append(spectral_contrast)\n",
        "            tonnetz_list.append(tonnetz)\n",
        "            labels.append(label)\n",
        "\n",
        "    return mfccs_list, chroma_list, spectral_contrast_list, tonnetz_list, labels\n",
        "\n",
        "# Function to prepare data\n",
        "def prepare_data(feature_dir):\n",
        "    # Load features from saved files\n",
        "    mfccs_list, chroma_list, spectral_contrast_list, tonnetz_list, labels = load_features_from_files(feature_dir)\n",
        "\n",
        "    # Encode labels\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(labels)\n",
        "\n",
        "    # Save LabelEncoder\n",
        "    with open('label_encoder.pkl', 'wb') as f:\n",
        "        pickle.dump(le, f)\n",
        "\n",
        "    # Pad sequences to ensure uniform input length for each feature type\n",
        "    max_length = max(len(x) for x in mfccs_list)\n",
        "    mfccs_list = np.array([np.pad(x, ((0, max_length - len(x)), (0, 0), (0, 0)), mode='constant') for x in mfccs_list])\n",
        "    chroma_list = np.array([np.pad(x, ((0, max_length - len(x)), (0, 0), (0, 0)), mode='constant') for x in chroma_list])\n",
        "    spectral_contrast_list = np.array([np.pad(x, ((0, max_length - len(x)), (0, 0), (0, 0)), mode='constant') for x in spectral_contrast_list])\n",
        "    tonnetz_list = np.array([np.pad(x, ((0, max_length - len(x)), (0, 0), (0, 0)), mode='constant') for x in tonnetz_list])\n",
        "\n",
        "    # Split the data\n",
        "    mfccs_train, mfccs_test, y_train, y_test = train_test_split(mfccs_list, y_encoded, test_size=0.2, random_state=42)\n",
        "    chroma_train, chroma_test = train_test_split(chroma_list, test_size=0.2, random_state=42)\n",
        "    spectral_contrast_train, spectral_contrast_test = train_test_split(spectral_contrast_list, test_size=0.2, random_state=42)\n",
        "    tonnetz_train, tonnetz_test = train_test_split(tonnetz_list, test_size=0.2, random_state=42)\n",
        "\n",
        "    return (mfccs_train, chroma_train, spectral_contrast_train, tonnetz_train, y_train), \\\n",
        "           (mfccs_test, chroma_test, spectral_contrast_test, tonnetz_test, y_test), le\n",
        "\n",
        "# Example usage\n",
        "feature_dir = '/content/drive/MyDrive/SMLRAAG_features'  # Update this path to your feature directory\n",
        "(mfccs_train, chroma_train, spectral_contrast_train, tonnetz_train, y_train), \\\n",
        "(mfccs_test, chroma_test, spectral_contrast_test, tonnetz_test, y_test), le = prepare_data(feature_dir)\n",
        "\n",
        "# Print shapes of the data for debugging\n",
        "print(\"Number of training samples:\", len(mfccs_train))\n",
        "print(\"Number of testing samples:\", len(mfccs_test))\n",
        "\n",
        "# Define input shapes based on the actual data shapes\n",
        "input_shape_mfccs = mfccs_train.shape[1:]\n",
        "input_shape_chroma = chroma_train.shape[1:]\n",
        "input_shape_spectral_contrast = spectral_contrast_train.shape[1:]\n",
        "input_shape_tonnetz = tonnetz_train.shape[1:]\n",
        "\n",
        "input_mfccs = Input(shape=input_shape_mfccs)\n",
        "input_chroma = Input(shape=input_shape_chroma)\n",
        "input_spectral_contrast = Input(shape=input_shape_spectral_contrast)\n",
        "input_tonnetz = Input(shape=input_shape_tonnetz)\n",
        "\n",
        "# TCN branches for each input using Conv1D\n",
        "def tcn_branch(input_layer):\n",
        "    reshaped_input = Reshape((input_layer.shape[1] * input_layer.shape[2], input_layer.shape[3]))(input_layer)\n",
        "    conv = Conv1D(32, kernel_size=3, activation='relu', kernel_regularizer=l2(0.001))(reshaped_input)\n",
        "    conv = BatchNormalization()(conv)\n",
        "    conv = MaxPooling1D(pool_size=2)(conv)\n",
        "    conv = Dropout(0.6)(conv)\n",
        "    lstm = Bidirectional(LSTM(64, return_sequences=False, kernel_regularizer=l2(0.001)))(conv)\n",
        "    lstm = BatchNormalization()(lstm)\n",
        "    return lstm\n",
        "\n",
        "tcn_mfccs = tcn_branch(input_mfccs)\n",
        "tcn_chroma = tcn_branch(input_chroma)\n",
        "tcn_spectral_contrast = tcn_branch(input_spectral_contrast)\n",
        "tcn_tonnetz = tcn_branch(input_tonnetz)\n",
        "\n",
        "# Concatenate the flattened layers\n",
        "combined = Concatenate()([tcn_mfccs, tcn_chroma, tcn_spectral_contrast, tcn_tonnetz])\n",
        "\n",
        "# Apply Dense and Dropout layers\n",
        "dense = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(combined)\n",
        "dense = Dropout(0.6)(dense)\n",
        "# Output layer\n",
        "output = Dense(3, activation='softmax')(dense)  # 3 classes - Bhairav, Malkans, and Yaman\n",
        "\n",
        "# Build and compile the model\n",
        "model = Model(inputs=[input_mfccs, input_chroma, input_spectral_contrast, input_tonnetz], outputs=output)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "# Print model summary for debugging\n",
        "print(model.summary())\n",
        "\n",
        "# Prepare the data for training\n",
        "train_data = [mfccs_train, chroma_train, spectral_contrast_train, tonnetz_train]\n",
        "test_data = [mfccs_test, chroma_test, spectral_contrast_test, tonnetz_test]\n",
        "\n",
        "# Early stopping and reduce learning rate on plateau\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "# Learning rate scheduler\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch > 10:\n",
        "        return lr * 0.5\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_data, y_train,\n",
        "                    epochs=50, batch_size=32, validation_data=(test_data, y_test),\n",
        "                    callbacks=[early_stopping, reduce_lr, lr_scheduler])\n",
        "\n",
        "# Save the model\n",
        "model.save('raag_recognition_model.keras')\n",
        "\n",
        "# Save the label encoder\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(le, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prediction**"
      ],
      "metadata": {
        "id": "9BnOVbK_DEqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "\n",
        "# Load the trained model and the label encoder\n",
        "model = load_model('/content/raag_recognition_model.keras')\n",
        "with open('label_encoder.pkl', 'rb') as f:\n",
        "    le = pickle.load(f)\n",
        "\n",
        "def augment_audio(y, sr):\n",
        "    # Time stretching\n",
        "    if np.random.random() < 0.5:\n",
        "        rate = np.random.uniform(0.9, 1.1)  # ±10% speed change\n",
        "        y = librosa.effects.time_stretch(y, rate=rate)\n",
        "\n",
        "    # Pitch shifting\n",
        "    if np.random.random() < 0.5:\n",
        "        n_steps = np.random.randint(-2, 3)  # ±2 semitones\n",
        "        y = librosa.effects.pitch_shift(y, sr=sr, n_steps=n_steps)\n",
        "\n",
        "    # Adding noise\n",
        "    if np.random.random() < 0.5:\n",
        "        noise = np.random.normal(0, 0.005, y.shape)\n",
        "        y = y + noise\n",
        "\n",
        "    return y\n",
        "\n",
        "def extract_features(file_path, segment_length=2, hop_length=1, sr=22050):\n",
        "    y, sr = librosa.load(file_path, sr=sr)\n",
        "    y = augment_audio(y, sr)\n",
        "    segment_samples = int(segment_length * sr)\n",
        "    hop_samples = int(hop_length * sr)\n",
        "\n",
        "    mfccs_list = []\n",
        "    chroma_list = []\n",
        "    spectral_contrast_list = []\n",
        "    tonnetz_list = []\n",
        "\n",
        "    for start in range(0, len(y), hop_samples):\n",
        "        end = start + segment_samples\n",
        "        segment = y[start:end]\n",
        "\n",
        "        # Pad the segment if it's shorter than the required length\n",
        "        if len(segment) < segment_samples:\n",
        "            segment = np.pad(segment, (0, segment_samples - len(segment)), mode='constant')\n",
        "\n",
        "        mfccs = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=13).T\n",
        "        chroma = librosa.feature.chroma_stft(y=segment, sr=sr).T\n",
        "        spectral_contrast = librosa.feature.spectral_contrast(y=segment, sr=sr).T\n",
        "        tonnetz = librosa.feature.tonnetz(y=segment, sr=sr).T\n",
        "\n",
        "        mfccs_list.append(mfccs)\n",
        "        chroma_list.append(chroma)\n",
        "        spectral_contrast_list.append(spectral_contrast)\n",
        "        tonnetz_list.append(tonnetz)\n",
        "\n",
        "    return np.array(mfccs_list), np.array(chroma_list), np.array(spectral_contrast_list), np.array(tonnetz_list)\n",
        "\n",
        "def pad_or_truncate(features, max_length):\n",
        "    if features.shape[0] < max_length:\n",
        "        return np.pad(features, ((0, max_length - features.shape[0]), (0, 0), (0, 0)), mode='constant')\n",
        "    else:\n",
        "        return features[:max_length]\n",
        "\n",
        "def pad_features(mfccs, chroma, spectral_contrast, tonnetz, max_length):\n",
        "    mfccs = pad_or_truncate(mfccs, max_length)\n",
        "    chroma = pad_or_truncate(chroma, max_length)\n",
        "    spectral_contrast = pad_or_truncate(spectral_contrast, max_length)\n",
        "    tonnetz = pad_or_truncate(tonnetz, max_length)\n",
        "    return mfccs, chroma, spectral_contrast, tonnetz\n",
        "\n",
        "def predict_raag(audio_path):\n",
        "    # Extract features from the input audio file\n",
        "    mfccs, chroma, spectral_contrast, tonnetz = extract_features(audio_path)\n",
        "\n",
        "    # Pad or truncate sequences to the expected maximum length\n",
        "    max_length = 32  # Update this to match your expected maximum length\n",
        "    mfccs, chroma, spectral_contrast, tonnetz = pad_features(mfccs, chroma, spectral_contrast, tonnetz, max_length)\n",
        "\n",
        "    # Prepare the data for prediction\n",
        "    mfccs = np.expand_dims(mfccs, axis=0)\n",
        "    chroma = np.expand_dims(chroma, axis=0)\n",
        "    spectral_contrast = np.expand_dims(spectral_contrast, axis=0)\n",
        "    tonnetz = np.expand_dims(tonnetz, axis=0)\n",
        "\n",
        "    # Predict the raag\n",
        "    predictions = model.predict([mfccs, chroma, spectral_contrast, tonnetz])\n",
        "    predicted_label = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Decode the label to get the raag name\n",
        "    raag_name = le.inverse_transform(predicted_label)\n",
        "\n",
        "    return raag_name[0]\n",
        "\n",
        "# Example usage\n",
        "audio_file_path = '/content/drive/MyDrive/SEGSMLRAGA/test data raga/Malkans 12 vocal aroh.wav'  # Update this path to your audio file\n",
        "predicted_raag = predict_raag(audio_file_path)\n",
        "print(f'The predicted raag is: {predicted_raag}')\n"
      ],
      "metadata": {
        "id": "0_z4nB3O-v4M"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}